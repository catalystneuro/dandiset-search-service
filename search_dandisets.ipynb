{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f770e71-5f6c-43d2-9c4d-4ab796c3c232",
   "metadata": {},
   "source": [
    "# Identify Dandisets relevant to a scientific question\n",
    "\n",
    "\n",
    "## Motivation\n",
    "\n",
    "We want to provide a system that, based on the user's questions, suggests dandisets that could be of relevance. The hope is that ChatGPT will be able to use semantic information of the question and return better results than simple text matching.\n",
    "\n",
    "## Plan of action\n",
    " \n",
    "\n",
    "### 1. Collect metadata from dandisets.\n",
    "<img src=\"step1_embed_dandiset_metadata.jpg\" style=\"width: 700px;\" />\n",
    "For each Dandiset:\n",
    "\n",
    "- get name, description, \n",
    "- get assets summary: approaches, measurement techniques, variables measured\n",
    "- for species, we can get accurate info from NCBITaxon, if it's included\n",
    "- Use OpenAI ada-002 to vectorize each metadata\n",
    "- Store the vectors in Qdrant, have the original dandiset id as object metadata for each vector\n",
    "\n",
    "### 2. Process user questions\n",
    "<img src=\"step2_do_search.jpg\" style=\"width: 700px;\" />\n",
    "\n",
    "- User queries can come in the form of questions, e.g.: \"Which datasets can I use to investigate the effects of drug YYYY on cells of type XXXX?\"\n",
    "- For method 1, the question is passed directly to a semantic embedding API using OpenAI.\n",
    "- For method 2, a prompt instructs the LLM to extract useful neuroscience research-related keywords from the question, and proceed to use the semantic search engine. We can achieve this using [OpenAI functions](https://openai.com/blog/function-calling-and-other-api-updates)\n",
    "- (simple approach) We return the dandiset IDs present in the top results \n",
    "- (advanced approach) We gather the text content of the collected metadata for the dandisets in the top results and include them in a prompt together with the user's original question and a default instruction such as: \"Given the user question and the listed reference datasets, which datasets could help address the user's question, and why?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a4a05",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -r requirements.txt\n",
    "export OPENAI_API_KEY=<your-openai-api-key>\n",
    "docker run -p 6333:6333 -v ~/qdrant_storage:/qdrant/storage qdrant/qdrant:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa66ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568c49f-aee0-4e01-a2cf-3761df040a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rest.clients.dandi import DandiClient\n",
    "from rest.clients.qdrant import QdrantClient\n",
    "from rest.clients.openai import OpenaiClient\n",
    "import json\n",
    "\n",
    "dandi_client = DandiClient()\n",
    "qdrant_client = QdrantClient(host=\"http://localhost\")\n",
    "openai_client = OpenaiClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bed570-35cb-455f-8f19-93e2f4873bb1",
   "metadata": {},
   "source": [
    "# Extract Dandisets metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260b3d0-15ad-4b90-a228-b4f44113a3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all dandisets metadata\n",
    "all_metadata = dandi_client.get_all_dandisets_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3444f-fc72-43bf-855f-d9dc23b2c60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract only relevant text fields from metadata\n",
    "all_metadata_formatted = dandi_client.collect_relevant_metadata(metadata_list=all_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0993e90-c9ae-4fa8-a6c5-598e2a3c2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of items: \", len(all_metadata_formatted))\n",
    "all_metadata_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a82e3-321b-4bed-986d-1067133919a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dandi_client.stringify_relevant_metadata(all_metadata_formatted[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac46414b-9e5d-4396-b339-cb14d777aecf",
   "metadata": {},
   "source": [
    "# Vector embeddings\n",
    "\n",
    "At this step, we generate vector embeddings for the formatted metadata from each dandiset. After that, we insert the combination of vectors + payload (metadata information) to Qdrant.\n",
    "To run the cells below, you must have:\n",
    "- `OPENAI_API_KEY` set as environment variable\n",
    "- Qdrant service running [ref](https://qdrant.tech/documentation/quick-start/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62629b61-de23-45c8-a9cd-c9dc9f90ac54",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate vector embeddings all items in formatted metadata list\n",
    "# This can be slow and costs a few cents per run, so it's recommended to save results to disk and load it later on\n",
    "emb = openai_client.get_embeddings(\n",
    "    metadata_list=all_metadata_formatted,\n",
    "    # max_num_sets=10,\n",
    "    save_to_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3f295-f5ab-457d-94bb-1d58bb8850dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or load them from a file, if already previously produced\n",
    "with open(\"data/qdrant_points.json\", \"r\") as file:\n",
    "    emb = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b839cda-0890-470b-b531-c7209740e388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Produced {len(emb)} embedding points for {len(all_metadata_formatted)} dandisets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274cd41-837b-4588-aae4-73f50c50b6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Qdrant collection\n",
    "qdrant_client.create_collection(collection_name=\"dandi_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc1463-fb5c-4008-be35-a15b83e178ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Populate collection with points\n",
    "qdrant_client.add_points_to_collection(collection_name=\"dandi_collection\", embeddings_objects=emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f08d74-218c-4a9c-ac82-e96612386d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = qdrant_client.get_collection_info(\"dandi_collection\")\n",
    "print(f\"Inserted {info['points_count']} points to Qdrant collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9021e66-2792-4741-82a5-11396221a51b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vectorize user questions\n",
    "\n",
    "At this step, we handle users input, with the goal of finding the most relevant dandisets for their questions. \n",
    "\n",
    "We test two vectorization options:\n",
    "- vectorize the entire question\n",
    "- extract relevant keywords from user's questions, vectorize these keywords\n",
    "\n",
    "Then perform a similarity search against our vector database, to gather the most semantically similar points to the user's question.\n",
    "\n",
    "Finally, we include the most semantically similar results and the user's input into a prompt which instructs the LLM to further refine the answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998d2da-9276-492e-8cc2-704a851017ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai import (\n",
    "    keywords_extraction, \n",
    "    prepare_keywords_for_semantic_search, \n",
    "    add_ordered_similarity_results_to_prompt, \n",
    "    get_llm_chat_answer\n",
    ")\n",
    "from utils.qdrant import query_all_keywords, query_from_user_input\n",
    "from utils.pipeline import prepare_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f114939-04fe-4d97-b7f5-b78e918176c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize user's input and query similar Qdrant points\n",
    "user_input = \"I am interested in the tuning properties of glial cells. Are there any good dandisets for studying that?\"\n",
    "\n",
    "ordered_similarity_results = query_from_user_input(text=user_input, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271e3d2-2002-4ea9-aa9e-03ffffcf482f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dandisets_text = add_ordered_similarity_results_to_prompt(similarity_results=ordered_similarity_results)\n",
    "prompt = prepare_prompt(user_input=user_input, dandisets_text=dandisets_text, model=\"gpt-3.5-turbo-16k\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04043bb7-f179-4baa-854f-daacd50bc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = get_llm_chat_answer(prompt=prompt, model=\"gpt-3.5-turbo-16k\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487d5c9-c483-45a2-ae09-bdb7f8f7469b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03596dc9-b859-4cbf-a9cd-c68ab78892df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A second approach would be to first extract neuroscience-related keywords from user's questions\n",
    "keywords = keywords_extraction(user_input=user_input)\n",
    "\n",
    "# Join the results in a list of strings, before semantic search\n",
    "keywords_2 = prepare_keywords_for_semantic_search(keywords)\n",
    "keywords_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba5ff7-f792-4f3a-8eed-7b4129ebc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query similar entries for each keyword, accumulate the scores for repeated results\n",
    "ordered_similarity_results = query_all_keywords(keywords_2, top_k=15)\n",
    "ordered_similarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41eef63-b8b2-42b8-96b2-15a2d288da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare a prompt instructing the LLM to suggest the most relevant dandisets based on user's input\n",
    "dandisets_text = add_ordered_similarity_results_to_prompt(similarity_results=ordered_similarity_results)\n",
    "prompt = prepare_prompt(user_input=user_input, dandisets_text=dandisets_text, model=\"gpt-3.5-turbo-16k\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2716a2-6cb2-47cf-beee-b4c0bef08258",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = get_llm_chat_answer(prompt=prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab9ff9-4170-4e3b-b9ce-98a6eb7de929",
   "metadata": {},
   "source": [
    "# Comparison of methods\n",
    "\n",
    "Here we compare the results of both methods for a variety of possible questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c494d1e-6ee6-47b8-9d97-167ca494b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pipeline import suggest_relevant_dandisets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a87f25-da8b-4e7a-b138-34cf498b1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I want to study natural movement in humans\"\n",
    "\n",
    "suggestions = suggest_relevant_dandisets(user_input=user_input, model=\"gpt-3.5-turbo-16k\", method=1)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161f960-7026-4ff6-970e-121c77d93b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = suggest_relevant_dandisets(user_input=user_input, model=\"gpt-3.5-turbo-16k\", method=2)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d4bdb-41a7-4b05-a7e9-59fd77ff4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Are there any datasets that have electrophysiology recordings of a rodent navigating a maze?\"\n",
    "\n",
    "suggestions = suggest_relevant_dandisets(user_input=user_input, model=\"gpt-3.5-turbo-16k\", method=1)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1d89a-44fb-41c4-bbbe-832965677341",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = suggest_relevant_dandisets(user_input=user_input, model=\"gpt-3.5-turbo-16k\", method=2)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa2e19-3019-4a29-b4ce-816428ecb893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
